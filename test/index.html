<!DOCTYPE html>
<html>
<head>
    <meta content="IE=edge" http-equiv="X-UA-Compatible"/>
    <meta content="text/html;charset=utf-8" http-equiv="Content-Type"/>
    <link data-name="vs/editor/editor.main" href="../node_modules/monaco-editor-core/dev/vs/editor/editor.main.css"
          rel="stylesheet">
    <script src="../node_modules/vscode-languageserver-types/lib/umd/main.d.ts"></script>
</head>
<body>

<h2>Monaco Editor JSON test page</h2>
<div id="container" style="width:800px;height:600px;border:1px solid grey"></div>

<script>
  // Loading basic-languages to get the json language definition
  var paths = {
    // 'vs/basic-languages': '../node_modules/monaco-languages/release/dev',
    'vs/language/jsonnet': '../out/amd',
    'jsonc-parser': '../node_modules/jsonc-parser/lib/umd/main',
    'vscode-json-languageservice': '../node_modules/vscode-json-languageservice/lib/umd/jsonLanguageService',
    'vscode-languageserver-types': '../node_modules/vscode-languageserver-types/lib/umd/main',
    'vscode-languageserver-textdocument': '../node_modules/vscode-languageserver-textdocument/lib/umd/main',
    'jsonLanguageTypes': '../node_modules/vscode-json-languageservice/lib/umd/jsonLanguageTypes',
    'vscode-nls': '../out/amd/fillers/vscode-nls',
    'vscode-uri': '../node_modules/vscode-uri/lib/umd/index',
    'services': '../node_modules/vscode-json-languageservice/lib/umd/services',
    'parser': '../node_modules/vscode-json-languageservice/lib/umd/parser',
    'utils': '../node_modules/vscode-json-languageservice/lib/umd/utils',
    'impl': '../node_modules/jsonc-parser/lib/umd/impl',
    'vs/base/worker': '../node_modules/monaco-editor-core/dev/vs/base/worker',
  }
  if (document.location.protocol === 'http:') {
    // Add support for running local http server
    let testIndex = document.location.pathname.indexOf('/test/')
    if (testIndex !== -1) {
      let prefix = document.location.pathname.substr(0, testIndex)
      paths['vs/language/jsonnet'] = prefix + '/out/amd'
    }
  }
  var require = {
    paths: paths
  }
</script>
<script src="../node_modules/monaco-editor-core/dev/vs/loader.js"></script>
<script src="../node_modules/monaco-editor-core/dev/vs/editor/editor.main.nls.js"></script>
<script src="../node_modules/monaco-editor-core/dev/vs/editor/editor.main.js"></script>

<script>
  require([
      // 'vs/basic-languages/monaco.contribution',
      'vs/language/jsonnet/monaco.contribution'
    ], function () {
      const files = {
        // 'README.md': '# Rakam API Integration\n\n## How does it work?\n\nRakam ingests all the event data into a table called `EVENTS`. This recipe maps the data, extract your event schema and create models from your events. \nAll your event properties will be updated upon recipe install/upgrade. If you started collecting a new event and do not see it as a model or a property, you can upgrade the recipe by re-running the `event schema` config. \n\nThe recipe contains the following models:\n\n* `all_events` model that contains all the events. It has an additional `event_type` dimension so you can see how your data is distributed across different event types.\n* Each event type has it\'s own model with the event its event properties. The schema is discovered via the `event_schema` config variable.\n\n## Adding a common metric to all events\n[./common_schema.libsonnet](common_schema.libsonnet) has `measures`, `dimensions`, and `properties` that applies to `all_events` and all custom event models. \nIf you want to add a metric that should be visible in all these events, you can add it there.\n\n* `measures`: The measures will show up in the measures of segmentation in all the models. If you have a business metric that applies all your events such as `Number of users`, `Revenue`, etc. you can add it here.\n* `properties`: If you want to make an event property visible in `all_events` and all other custom event models, you can add it here. Additionally, you can add label, category or force a type for an event property using this key.\n* `dimensions`: If you want to add a custom dimension to all models such as a computed property (i.e. `{{dimension.property1}} * {{dimension.property2}}`), you can add it here.\n\n## Adding a metric to an individual event\nSimilar to the common file, there is [./predefined_schema.libsonnet](custom_schema.libsonnet) that includes event_type to model definitions. \nThe object keys correspond to event type, the object values `measures` and `dimensions` and will be applied to your custom event upon recipe update.\n\n* `measures`: If you have a measure that can be applies to a specific event type, you can add it here. An example would be `Unique Pageviews` for `pageview model`.\n* `properties`: All your event properties will be updated upon recipe install/upgrade so you don\'t actually need to write your properties here. However; in case you want to add label or description to an event type or its property, you can define them here. Moreover; you can categorize them by adding `category` property in this section.\n\n',
        '_config.jsonnet': '{\n  version: 1.1,\n  label: \'Rakam API\',\n  description: \'It automatically creates models from your collections.\',\n  variables: {\n    target: {\n      label: \'Events Table\',\n      type: \'table\',\n      default: { table: \'EVENTS\' },\n    },\n    event_schema: {\n      type: \'sql\',\n      parent: \'target\',\n      description: \'The event schema in your Snowflake Warehouse\',\n      options: {\n        sql: |||\n          SELECT EVENT_NAME as "n", ANY_VALUE(EVENT_DB) as "db", ARRAY_AGG(OBJECT_CONSTRUCT(\'db\', PROP_DB, \'n\', PROP_NAME, \'t\', TYPE)) as "props"\n          FROM (\n                  SELECT\n                  DISTINCT E.EVENT_TYPE as EVENT_DB,\n                  LOWER(LTRIM(REGEXP_REPLACE(REGEXP_REPLACE(E.EVENT_TYPE, \'([a-z])([A-Z])\', \'\\1_\\2\'), \'[^a-zA-Z0-9_]\', \'\'), \'_\')) as EVENT_NAME,\n                  F.KEY as PROP_DB,\n                  LOWER(LTRIM(REGEXP_REPLACE(REGEXP_REPLACE(F.KEY, \'([a-z])([A-Z])\', \'\\1_\\2\'), \'[^a-zA-Z0-9_]\', \'\'), \'_\')) as PROP_NAME,\n                  MODE(TYPEOF(f.VALUE)) OVER (PARTITION BY EVENT_DB, PROP_DB, TYPEOF(f.VALUE)) as TYPE\n              FROM\n                  (select * from events where _TIME between DATEADD(DAY, -15, current_timestamp) and current_timestamp limit 2000000) E,\n                  LATERAL FLATTEN(PROPERTIES, RECURSIVE=>FALSE) F\n              WHERE\n                  \n                  TYPEOF(F.VALUE) IN (\'BOOLEAN\', \'DECIMAL\', \'DOUBLE\', \'INTEGER\', \'VARCHAR\')\n                  --AND REGEXP_LIKE(F.KEY, \'^[a-zA-Z0-9]*$\')\n                  AND EVENT_TYPE NOT IN (\'$invalid_schema\', \'$identify\') \n          ) d\n          GROUP BY 1\n        |||,\n      },\n    },\n  },\n  tags: [\'event-analytics\'],\n  databases: [\'snowflake\'],\n}\n',
        'all_events.model.jsonnet': '{\n' +
          '  name : "onboarding",\n' +
          '  target : {\n' +
          '    database : "rakam",\n' +
          '    schema : "supersonic",\n' +
          '    table : "onboarding"\n' +
          '  },\n' +
          '  mappings : {\n' +
          '    eventTimestamp : "_time",\n' +
          '    incremental : "$server_time",\n' +
          '    userId : "_user",\n' +
          '    deviceId : "device_id"\n' +
          '  },\n' +
          '  dimensions : {\n' +
          '    event_type : {\n' +
          '      type : "string",\n' +
          '      column : "event_type",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    id : {\n' +
          '      type : "string",\n' +
          '      column : "id",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    sign_up_type : {\n' +
          '      type : "string",\n' +
          '      column : "sign_up_type",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    _time : {\n' +
          '      timeframes : [ "hour", "day", "week", "month", "dayOfWeek" ],\n' +
          '      type : "timestamp",\n' +
          '      column : "_time",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    device_id : {\n' +
          '      type : "string",\n' +
          '      column : "device_id",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    timestamp : {\n' +
          '      timeframes : [ "hour", "day", "week", "month", "dayOfWeek" ],\n' +
          '      type : "timestamp",\n' +
          '      column : "timestamp",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    event_name : {\n' +
          '      type : "string",\n' +
          '      column : "event_name",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    device_type : {\n' +
          '      type : "string",\n' +
          '      column : "device_type",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    type : {\n' +
          '      type : "string",\n' +
          '      column : "type",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    user_id : {\n' +
          '      type : "string",\n' +
          '      column : "user_id",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    device_connection : {\n' +
          '      type : "string",\n' +
          '      column : "device_connection",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    app_build_type : {\n' +
          '      type : "string",\n' +
          '      column : "app_build_type",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    view_path : {\n' +
          '      type : "string",\n' +
          '      column : "view_path",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    app_version : {\n' +
          '      type : "string",\n' +
          '      column : "app_version",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    platform : {\n' +
          '      type : "string",\n' +
          '      column : "platform",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    _user : {\n' +
          '      type : "string",\n' +
          '      column : "_user",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    status : {\n' +
          '      type : "string",\n' +
          '      column : "status",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    server_time : {\n' +
          '      timeframes : [ "hour", "day", "week", "month", "dayOfWeek" ],\n' +
          '      type : "timestamp",\n' +
          '      column : "$server_time",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    gender : {\n' +
          '      type : "string",\n' +
          '      column : "gender",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    year : {\n' +
          '      type : "string",\n' +
          '      column : "year",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    location : {\n' +
          '      type : "string",\n' +
          '      column : "location",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    ab_testing_experiment : {\n' +
          '      type : "string",\n' +
          '      column : "ab_testing_experiment",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    subscription : {\n' +
          '      type : "double",\n' +
          '      sqfl: \'test\',\n' +
          '      collumn : "subscriptions",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      }\n' +
          '    },\n' +
          '    interests : {\n' +
          '      type : "double",\n' +
          '      column : "interests"\n' +
          '    }\n' +
          '  },\n' +
          '  measures : {\n' +
          '    all_rows : {\n' +
          '      label : "All onboarding",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      },\n' +
          '      aggregation : "count",\n' +
          '      type : "double"\n' +
          '    },\n' +
          '    all_unique_devices : {\n' +
          '      label : "Unique Devices",\n' +
          '      description : "Count Unique Devices",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      },\n' +
          '      column : "device_id",\n' +
          '      aggregation : "countUnique",\n' +
          '      type : "double"\n' +
          '    },\n' +
          '    all_unique_users : {\n' +
          '      label : "Unique Users",\n' +
          '      description : "Count Unique Users",\n' +
          '      reportOptions : {\n' +
          '        formatNumbers : true\n' +
          '      },\n' +
          '      column : "_user",\n' +
          '      aggregation : "countUnique",\n' +
          '      type : "double"\n' +
          '    }\n' +
          '  }\n' +
          '}',
        // 'common_schema.libsonnet': '{\n  measures: {\n    unique_users: {\n      aggregation: \'countUnique\',\n      sql: \'{{dimension.user}}\',\n    },\n    unique_devices: {\n      aggregation: \'countUnique\',\n      sql: \'{{dimension.device_id}}\',\n    },\n    unique_sessions: {\n      aggregation: \'countUnique\',\n      sql: \'{{dimension.session_id}}\',\n    },\n    total_events: {\n      aggregation: \'count\',\n    },\n    revenue: {\n      aggregation: \'sum\',\n      sql: \'{{dimension.value}}\'\n    },\n    revenue_in_this_week: {\n      aggregation: \'sum\',\n      sql: \'{{dimension.value}}\',\n      filters: [\n        { dimension: \'time\', operator: \'between\', value: \'P1W\', valueType: \'timestamp\' },\n      ],\n    },\n    revenue_in_this_month: {\n      aggregation: \'sum\',\n      sql: \'{{dimension.value}}\',\n      filters: [\n        { dimension: \'time\', operator: \'between\', value: \'P1M\', valueType: \'timestamp\' },\n      ],\n    },\n    revenue_in_previous_week: {\n      aggregation: \'sum\',\n      sql: \'{{dimension.value}}\',\n      filters: [\n        { dimension: \'time\', operator: \'between\', value: \'P2W\', valueType: \'timestamp\' },\n        { dimension: \'time\', operator: \'lessThan\', value: \'P1W\', valueType: \'timestamp\' },\n      ],\n    },\n    revenue_in_previous_month: {\n      aggregation: \'sum\',\n      sql: \'{{dimension.value}}\',\n      filters: [\n        { dimension: \'time\', operator: \'between\', value: \'P2M\', valueType: \'timestamp\' },\n        { dimension: \'time\', operator: \'lessThan\', value: \'P1M\', valueType: \'timestamp\' },\n      ],\n    },\n  },\n  properties: {\n    value: {\n      label: \'Revenue\',\n      category: \'Aptoide\',\n      type: \'double\',\n    },\n    aptoide_package: {\n      category: \'Aptoide\',\n      type: \'string\',\n    },\n    _session_id: {\n      category: \'User\',\n      type: \'string\',\n    },\n    _device_id: {\n      category: \'User\',\n      type: \'string\',\n    },\n    __ip: {\n      category: \'User Location\',\n      type: \'string\',\n    },\n    _city: {\n      category: \'User Location\',\n      type: \'string\',\n    },\n    _region: {\n      category: \'User Location\',\n      type: \'string\',\n    },\n    _country_code: {\n      category: \'User Location\',\n      type: \'string\',\n    },\n    _latitude: {\n      category: \'User Location\',\n      type: \'string\',\n    },\n    _device_brand: {\n      category: \'User Location\',\n      type: \'string\',\n    },\n    _device_carrier: {\n      category: \'User Location\',\n      type: \'string\',\n    },\n    _device_family: {\n      category: \'User Location\',\n      type: \'string\',\n    },\n    _device_manufacturer: {\n      category: \'User Location\',\n      type: \'string\',\n    },\n    _device_model: {\n      category: \'User Location\',\n      type: \'string\',\n    },\n  },\n  mappings: {\n    eventTimestamp: \'time\',\n    userId: \'user\',\n    deviceId: \'device_id\',\n  },\n}\n',
        // 'custom_events.models.jsonnet': 'local common = import \'common_schema.libsonnet\';\nlocal predefined = import \'custom_schema.libsonnet\';\n\nlocal target = std.extVar(\'target\');\n\nlocal types = {\n  BOOLEAN: \'boolean\',\n  DECIMAL: \'double\',\n  DOUBLE: \'double\',\n  INTEGER: \'integer\',\n  VARCHAR: \'string\',\n};\n\nstd.map(function(event_type)\n  local event_name = event_type.n;\n  local db_name = event_type.db;\n\n  local defined = if std.objectHas(predefined, event_name) then predefined[event_name] else null;\n\n  local definedProperties = if defined != null && std.objectHas(defined, \'properties\') then defined.properties else {};\n  local dimensions_for_event = std.foldl(function(a, b) a + b, std.map(function(prop) {\n                                 [prop.n]: {\n                                   sql: \'cast({{TABLE}}.properties:"%(name)s" as %(type)s)\' % { type: prop.t, name: prop.db },\n                                   label: if std.objectHas(definedProperties, prop.n) && std.objectHas(definedProperties[prop.n], \'label\') then definedProperties[prop.n].label\n                                   else if std.objectHas(common.properties, prop.n) && std.objectHas(common.properties[prop.n], \'label\') then common.properties[prop.n].label\n                                   else null,\n                                   type: types[prop.t],\n                                   category: if std.objectHas(definedProperties, prop.n) && std.objectHas(definedProperties[prop.n], \'category\') then definedProperties[prop.n].category\n                                   else if std.objectHas(common.properties, prop.n) && std.objectHas(common.properties[prop.n], \'category\') then common.properties[prop.n].category\n                                   else if std.startsWith(prop.db, \'_\') then \'SDK\'\n                                   else \'Event Property\',\n                                 },\n                               }, std.parseJson(event_type.props)), {})\n                               +\n                               if defined != null && std.objectHas(defined, \'dimensions\') then defined.dimensions else {};\n  {\n    name: \'rakam_event_\' + event_name,\n    label: (if defined != null then \'[SDK] \' else \'\') + event_name,\n    sql: |||\n      select * from "%(database)s"."%(schema)s"."%(table)s" where event_type = \'%(db_name)s\'\n    ||| % { db_name: db_name, database: target.database, schema: target.schema, table: target.table },\n    measures: common.measures + if defined != null && std.objectHas(defined, \'measures\') then defined.measures else {},\n    mappings: common.mappings,\n    relations: if defined != null && std.objectHas(defined, \'relations\') then defined.relations else {},\n    category: \'Rakam Events\',\n    dimensions: dimensions_for_event + {\n    event_type: {\n      column: \'EVENT_TYPE\',\n      type: \'string\',\n    },\n    time: {\n      column: \'_TIME\',\n      description: \'\',\n      type: \'timestamp\',\n    },\n    server_time: {\n      column: \'_SERVER_TIME\',\n      description: \'\',\n      type: \'timestamp\',\n    },\n    user: {\n      column: \'_USER\',\n      type: \'string\',\n      description: \'\',\n    },\n  },\n  }, std.extVar(\'event_schema\'))\n',
        // 'custom_schema.libsonnet': 'local payment = {\n    measures: {\n      app_coin: {\n        sql: \'{{dimension.value}}\',\n        aggregation: \'sum\',\n      },\n      app_coin_in_euro: {\n        sql: \'0.02888766*{{dimension.value}}\',\n        aggregation: \'sum\',\n        reportOptions: {\n          suffix: \' EUR\'\n        }\n      },\n      app_coin_in_usd: {\n        sql: \'0.03194*{{dimension.value}}\',\n        aggregation: \'sum\',\n        reportOptions: {\n          suffix: \' USD\'\n        }\n      }\n    },\n    // define category and descriptions for properties\n    properties: {\n      value: {\n        category: \'Revenue\',\n        type: \'double\'\n      }\n    },\n    dimensions: {\n      example_computed_dimension: {\n        category: \'Example Category\',\n        type: \'string\',\n        sql: \'concat({{dimension.product_name}}, {{dimension.product_id}})\',\n      },\n    }\n  };\n\n{\n  wallet_payment_conclusion: payment,\n  wallet_top_up_conclusion: payment,\n  pageview: {\n    measures: {\n      time_on_page: {\n        aggregation: \'average\',\n        sql:\'LEAST(GREATEST(0, {{dimension.time_on_page}}), 1000)\',\n        description: \'The duration spent on the page when the user visits the pages. If the value is `null`, then the users bounced and the sample data is not enough to calculate the time on page.\',\n        filters: [\n          {dimension: \'time_on_page\', valueType: \'unknown\', operator: \'isSet\'}\n        ],\n        reportOptions: {\n          suffix: \' seconds\'\n        },\n      }\n    }\n  },\n  session_start: {\n    measures: {\n      unique_users_today: {\n        aggregation: \'countUnique\',\n        sql: \'{{dimension.user}}\',\n        filters: [\n          { dimension: \'time\', operator: \'between\', value: \'P1D\', valueType: \'timestamp\' },\n        ],\n      },\n      unique_users__week: {\n        aggregation: \'countUnique\',\n        sql: \'{{dimension.user}}\',\n\n\n        ///testststst\n        filters: [\n          { dimension: \'time\', operator: \'between\', value: \'P1W\', valueType: \'timestamp\' },\n        ],\n      },\n    },\n    dimensions: {\n      week_over_week: {\n        category: \'Period-over-period\',\n        sql: "case when (mod(current_date() - cast({{TABLE}}._time as date), 7) = 0) then cast((current_date() - cast({{TABLE}}._time as date))/7 as number) || \' weeks ago\' else null end",\n        type: \'string\'\n      }\n    }\n  },\n  download: {\n    measures: {\n      yesterday_downloads: {\n        hidden: true,\n        aggregation: \'sum\',\n        sql: \'CASE WHEN {{dimension.time}} BETWEEN dateadd(day, -2, current_timestamp()) and dateadd(day, -1, current_timestamp()) then 1 else 0 end\'\n      },\n      today_downloads: {\n        hidden: true,\n        aggregation: \'sum\',\n        sql: \'CASE WHEN {{dimension.time}} BETWEEN dateadd(day, -1, current_timestamp()) and current_timestamp() then 1 else 0 end\'\n      },\n      last_week_downloads: {\n        hidden: true,\n        aggregation: \'sum\',\n        sql: \'CASE WHEN {{dimension.time}} BETWEEN dateadd(day, -8, current_timestamp()) and dateadd(day, -7, current_timestamp()) then 1 else 0 end\'\n      },\n      growth_today: {\n        label: \'Daily Donwload Growth\',\n        sql: \'CASE WHEN {{measure.yesterday_downloads}} > 500 then ({{measure.today_downloads}} - {{measure.yesterday_downloads}}) * 100 / {{measure.yesterday_downloads}} else 0 end\',\n        reportOptions: {\n          suffix: \'%\'\n        }\n      },\n      growth_this_week: {\n        label: \'Weekly Download Growth\',\n        sql: \'CASE WHEN {{measure.last_week_downloads}} > 500 then ({{measure.today_downloads}} - {{measure.last_week_downloads}}) * 100 / {{measure.last_week_downloads}} else 0 end\',\n        reportOptions: {\n          suffix: \'%\'\n        }\n      }\n    }\n  }\n}\n',
        // 'invalid_schema.model.jsonnet': 'local common = import \'common_schema.libsonnet\';\nlocal util = import \'util.libsonnet\'; \nlocal target = std.extVar(\'target\');\n\nlocal types = {\n  BOOLEAN: \'boolean\',\n  DECIMAL: \'double\',\n  DOUBLE: \'double\',\n  INTEGER: \'integer\',\n  VARCHAR: \'string\',\n};\n\nlocal dimensions = [\n  {\n    db: \'collection\',\n    n: \'collection\',\n    t: \'VARCHAR\',\n    desc: null,\n  },\n  {\n    db: \'property\',\n    n: \'property\',\n    t: \'VARCHAR\',\n    desc: \'The property the system failed to parse in the collection\',\n  },\n  {\n    db: \'type\',\n    n: \'type\',\n    t: \'VARCHAR\',\n    desc: \'The expected type for the field. The system failed to parse the value to this type.\',\n  },\n  {\n    db: \'event_id\',\n    n: \'event_id\',\n    t: \'VARCHAR\',\n    desc: \'The id of the corresponding event in the EVENTS table. You can use this id in order to join to that table and fix the historical data.\',\n  },\n  {\n    db: \'error_message\',\n    n: \'error_message\',\n    t: \'VARCHAR\',\n    desc: \'The error message thrown in the system parsing the property \',\n  },\n  {\n    db: \'encoded_value\',\n    n: \'encoded_value\',\n    t: \'VARCHAR\',\n    desc: \'aria-label="The invalid raw value encoded as JSON for that is sent to the API"\',\n  },\n];\n\n{\n  category: \'Rakam Events\',\n  name: \'rakam_invalid_schema\',\n  label: \'[System] Invalid Schema\',\n  description: \'Includes the parsing errors in the API. \',\n  sql: |||\n    select * from %(target)s where event_type = \'$invalid_schema\'\n  ||| % { target: util.generate_target_reference(target) },\n  measures: common.measures,\n  mappings: common.mappings,\n  dimensions: {\n    event_type: {\n      column: \'EVENT_TYPE\',\n      type: \'string\',\n    },\n    time: {\n      column: \'_TIME\',\n      description: \'\',\n      type: \'timestamp\',\n    },\n    server_time: {\n      column: \'_SERVER_TIME\',\n      description: \'\',\n      type: \'timestamp\',\n    },\n    user: {\n      column: \'_USER\',\n      type: \'string\',\n      description: \'\',\n    },\n  } + std.foldl(function(a, b) a + b, std.map(function(prop) {\n    [prop.n]: {\n      sql: \'{{TABLE}}.properties:"%(name)s"::%(type)s\' % { type: prop.t, name: prop.db },\n      category: if std.startsWith(prop.db, \'_\') then \'SDK\' else \'Event Property\',\n      type: types[prop.t],\n      description: prop.desc,\n    },\n  }, dimensions), {}),\n}\n',
        // 'user_attributes.jsonnet': '{\n  sql: |||\n    SELECT\n        DISTINCT F.KEY as PROP_DB,\n        LOWER(LTRIM(REGEXP_REPLACE(REGEXP_REPLACE(F.KEY, \'([a-z])([A-Z])\', \'\\1_\\2\'), \'[^a-zA-Z0-9_]\', \'\'), \'_\')) as PROP_NAME,\n        FALSE AS IS_IN_SET,\n        MODE(TYPEOF(f.VALUE)) OVER (PARTITION BY PROP_DB, TYPEOF(f.VALUE)) as TYPE\n    FROM\n        EVENTS E,\n        LATERAL FLATTEN(PROPERTIES:"$set", RECURSIVE=>FALSE) F\n    WHERE\n        _TIME > DATEADD(MINUTE, -60, current_timestamp)\n        AND TYPEOF(F.VALUE) IN (\'BOOLEAN\', \'DECIMAL\', \'DOUBLE\', \'INTEGER\', \'VARCHAR\')\n        AND EVENT_TYPE = \'$identify\'\n    UNION ALL\n    SELECT\n        DISTINCT F.KEY as PROP_DB,\n        LOWER(LTRIM(REGEXP_REPLACE(REGEXP_REPLACE(F.KEY, \'([a-z])([A-Z])\', \'\\1_\\2\'), \'[^a-zA-Z0-9_]\', \'\'), \'_\')) as PROP_NAME,\n        TRUE AS IS_IN_SET,\n        MODE(TYPEOF(f.VALUE)) OVER (PARTITION BY PROP_DB, TYPEOF(f.VALUE)) as TYPE\n    FROM\n        EVENTS E,\n        LATERAL FLATTEN(PROPERTIES, RECURSIVE=>FALSE) F\n    WHERE\n        _TIME > DATEADD(MINUTE, -60, current_timestamp)\n        AND TYPEOF(F.VALUE) IN (\'BOOLEAN\', \'DECIMAL\', \'DOUBLE\', \'INTEGER\', \'VARCHAR\')\n        AND EVENT_TYPE = \'$identify\'\n  |||,\n}\n'
      }

      let extVars = {_aq: '"', _db: 'snowflake'}

      const host = 'https://app.rakam.io'
      const schema = [
        {
          uri: 'http://docs.rakam.io/schema/model',
          fileMatch: ['*.model.json'],
          schema: {'$ref': host + '/schema/model.schema.json'}
        },
        {
          uri: 'http://docs.rakam.io/schema/models',
          fileMatch: ['*.models.json'],
          schema: {
            'type': 'array',
            'items': {'$ref': host + '/schema/model.schema.json'}
          }
        },
        {
          uri: 'http://docs.rakam.io/schema/config',
          fileMatch: ['_config.json'],
          schema: {'$ref': host + '/schema/config.schema.json'}
        }
        // {
        //   uri: 'https://docs.rakam.io/docs/compose/schema/dashboards.json',
        //   fileMatch: ['dashboard.json'],
        //   schema: dashboardSchema
        // },
        // {
        //   uri: 'https://docs.rakam.io/docs/compose/schema/dashboard.json',
        //   fileMatch: ['*.dashboards.json'],
        //   schema: {
        //     'type': 'array',
        //     'items': dashboardSchema
        //   }
        // }
      ]

      const libraries = {
        'util.libsonnet': `{
  generate_jinja_header(obj)::
    std.join('', ['{%% set %s = %s %%} ' % [f, std.manifestPython(obj[f])] for f in std.objectFields(obj)]),
  generate_model_name_from_file(name)::
    local parts = std.split(name, '/');
    std.strReplace(parts[std.length(parts) - 1], '.model.jsonnet', ''),
  generate_target_reference(target)::
    local alias_quote = std.extVar('_aq');
    std.join('.', std.map(function(x) alias_quote + x + alias_quote, std.filter(function(x) x != null, [
      if std.objectHas(target, 'database') then target.database else null,
      if std.objectHas(target, 'schema') then target.schema else null,
      target.table,
    ]))),
}`
      }
      monaco.languages.jsonnet.jsonnetDefaults.setDiagnosticsOptions({
        validate: true,
        allowComments: true,
        enableSchemaRequest: true,
        libraries: libraries,
        extVars: extVars,
        compilerUrl: '/test/main.wasm',
        schemas: schema.map(item => {
          return {
            fileMatch: item.fileMatch.map(v => `${v}net`),
            schema: item.schema,
            uri: item.uri
          }
        })
      })

      const models = {}
      Object
        .keys(files).forEach(file => {
        const uri = monaco.Uri.from({path: file, scheme: 'git'})
        models[file] = monaco.editor.createModel(files[file], null, uri)
      })
      console.log(models)
      window.models = models

      const editor = monaco.editor.create(document.getElementById('container'), {
        model: models['_config.jsonnet'],
        theme: 'vs-dark',
      })

      monaco.languages.jsonnet.getWorker().then(workerXhr => {
        return workerXhr().then(worker => {
          worker.compile(new monaco.Uri('git', null, '_config.jsonnet')).then(data => {
            // debugger
          })
        })
      })

      var commandId = editor.addCommand(0, function () {
        // services available in `ctx`
        alert('my command is executing!')

      }, '')

      // monaco.languages.registerCodeLensProvider('jsonnet', {
      //   provideCodeLenses: function (model, token) {
      //     if (model.uri.path === '_config.jsonnet') {
      //       const a = monaco.languages.jsonnet.getWorker().then(workerXhr => {
      //         return workerXhr().then(worker => {
      //           const ourPaths = [['version'], ['path']]
      //           return worker.getJsonPaths(new monaco.Uri('git', null, '_config.jsonnet'), ...ourPaths).then(jsonnetPaths => {
      //             debugger
      //             const codeLenses = []
      //             jsonnetPaths.forEach((range, idx) => {
      //               if (range == null) return
      //               let id = ourPaths[idx].join('.')
      //               codeLenses.push({
      //                 range: range,
      //                 id: id,
      //                 command: {
      //                   id: commandId,
      //                   title: id
      //                 }
      //               })
      //             })
      //
      //             return {lenses: codeLenses}
      //           })
      //         })
      //       })
      //
      //       console.log(a)
      //       a.then(c => console.log(c))
      //
      //       return a
      //     }
      //   },
      //   resolveCodeLens: function (model, codeLens, token) {
      //     return codeLens
      //   }
      // })
    }
  )
</script>

</body>
</html>
